# MLOps Deployment Project 🚀

This project implements a modular approach for machine learning operations (MLOps) using various tools and services. Below are the key components and tools used in this project:

## Modular Approach 🔧

The project follows a modular approach, organized into components and pipelines. It includes:

- **Config YAML File:** Contains configuration parameters for the project.
- **Components:** Individual modules or functions that perform specific tasks.
- **Pipelines:** Sequences of components orchestrated to execute machine learning workflows.

## Tools Used 🛠️

- **MLflow:** Used for model registry and management.
- **DVC (Data Version Control):** Utilized for pipeline orchestration and versioning data.
- **Dagshub:** Hosted repository for collaborative development and version control.
- **AWS Free Tier:** Utilized for cloud computing with a 1GB RAM instance.
- **Google Drive:** Used for storing project artifacts.
- **AWS EC2:** Hosting platform for deploying services and applications.
- **AWS ECR (Elastic Container Registry):** Used for storing and managing Docker container images.
- **Docker:** Containerization technology for packaging applications and dependencies.
- **Streamlit:** Web application framework used for interactive data visualization.

## Pipeline Image 📊

You can view the pipeline image below to understand the workflow:

![Pipeline Image](link-to-your-pipeline-image)

## Project Repository 📁

The complete project code and resources can be accessed on Dagshub:

[Link to Dagshub Repository](https://dagshub.com/harshpatel1242/MLOps_Deployment)

## AWS Services ☁️

The project utilizes AWS Free Tier services for cloud computing, including EC2 for hosting and ECR for Docker image management. Make sure to manage resources within the Free Tier limits.

## Artifact Storage 📂

All project artifacts, including data, models, and logs, are stored on Google Drive.

Feel free to explore the project repository for more details and contributions.
