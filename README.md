# MLOps Deployment Project 🚀

This project implements a modular approach for machine learning operations (MLOps) using various tools and services. Below are the key components and tools used in this project:

## Modular Approach 🔧

The project follows a modular approach, organized into components and pipelines. It includes:

- **Config YAML File:** Contains configuration parameters for the project.
- **Components:** Individual modules or functions that perform specific tasks.
- **Pipelines:** Sequences of components orchestrated to execute machine learning workflows.

## Tools Used 🛠️

- **MLflow:** Used for model registry and management.
- **DVC (Data Version Control):** Utilized for pipeline orchestration and versioning data.
- **Dagshub:** Hosted repository for collaborative development and version control.
- **AWS Free Tier:** Utilized for cloud computing with a 1GB RAM instance.
- **Google Drive:** Used for storing project artifacts.
- **AWS EC2:** Hosting platform for deploying services and applications.
- **AWS ECR (Elastic Container Registry):** Used for storing and managing Docker container images.
- **Docker:** Containerization technology for packaging applications and dependencies.
- **Streamlit:** Web application framework used for interactive data visualization.

## CI/CD with GitHub Actions 🚀

Continuous Integration and Continuous Deployment (CI/CD) pipelines are implemented using GitHub Actions. The pipelines automate the build, test, and deployment processes, delivering the project to AWS services.

[Check out CI/CD workflows](https://github.com/harshpatel1242/MLOps_Deployment/actions)

## Pipeline Flow 📊

![Pipeline Flow](https://github.com/harshpatel1242/MLOps_Deployment/blob/master/Pipeline_Flow.PNG)

## Project Repository 📁

The complete project code and resources can be accessed on Dagshub:

[Link to Dagshub Repository](https://dagshub.com/harshpatel1242/MLOps_Deployment)

## AWS Services ☁️

The project utilizes AWS Free Tier services for cloud computing, including EC2 for hosting and ECR for Docker image management. Make sure to manage resources within the Free Tier limits.

## Artifact Storage 📂

All project artifacts, including data, models, and logs, are stored on Google Drive.

Feel free to explore the project repository for more details and contributions.

## Data Access 📊

The project's data can be accessed from Google Drive using the following link:

[Google Drive Data Link](https://drive.google.com/file/d/1Q02T8c6-BRC32TbSFqZdLpR9UdVeVpHS/view?usp=drive_link)

